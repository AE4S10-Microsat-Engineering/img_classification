{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V-uUfu6n20n"
      },
      "source": [
        "# Train on MNIST - Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4_shxNsxOW4"
      },
      "source": [
        "This notebook is used to implement the training of a neural network for the [\"MNIST (\"Modified National Institute of Standards and Technology\")](http://yann.lecun.com/exdb/mnist/index.html) dataset. <br> To train our network, we use [PyTorch](https://pytorch.org/). <br> PyTorch implements a suit that allows you to implement a neural network and the backpropagation algorithm easily. <br>\n",
        "For aximum performance, we suggest to switch the computing resources to `GPU`. You can do that by clicking on the arrow on top-right of the screen, then `change runtype time`, and finally `T4 GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BayGv92FeGJQ"
      },
      "source": [
        "The next celll will install [torchvision](https://pytorch.org/vision/stable/index.html), which is needed to download and manage the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv6autZ4n4a5",
        "outputId": "69029850-34ab-4096-f0d2-ba222afbe4d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma_JWh-W-IF"
      },
      "source": [
        "## 1. - Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "Enabling autoreload of different packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "38QZieHiyZOK"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "### 1.1 Assignment imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-EQlMgLSyfzd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRKvCr7wz5yd"
      },
      "source": [
        "## 2. - Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOleOYbeBSC4"
      },
      "source": [
        "### 2.1 - Loading MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB2i_MUd0rrj"
      },
      "source": [
        "We now download load the dataset into 2 splits (`Train` and `Test`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv20ur2D0BIj",
        "outputId": "876c87b0-0f2b-474e-dffc-d5b21fd5f1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.53MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train split\n",
        "train_MNIST = datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor()\n",
        "                   ]))\n",
        "# Test split\n",
        "test_MNIST = datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlN1Md3nBoJ-"
      },
      "source": [
        "### 3.2 - Splitting Train into Train and Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7xOMuY9Bt2C"
      },
      "source": [
        "As discussed in the lecture slides, to train the model correctly we split the entire MNIST dataset into three splits to train our model:\n",
        "* **Train** : 71.43%\n",
        "* **Cross-Validation** : 14.23%\n",
        "* **Test**: 14.23% <br>\n",
        "\n",
        "You can also change the train/cross-validation percentage by changing the value of `cv_percentage` from its default value (`0.1666540669186616`). <br> <br>\n",
        "It is also possible to test a wrong splitting that leads to **overfitting**. Ovefitting occurs when the model fits the training split too tightly that is not able to generalize on the validation and test splits. To virtually creating overfitting, set the flag `test_overfitting` to `True`. If you do that, we will split the dataset so that all the images containing a `8` or a `9` will be not included in the training but in the cross-validation. In this condition, the model will be able to learn the data in the training set quite well. However, it will be not able to classify correctly the images containing `8` or a `9` since it did not see them during training. This is similar to the experience that  students might face when the explanations given in class do not cover topics requested in their homework. Overfitting is not only due to mistmatches between the data distributions of training and other splits. Later you will find a more detailed explanation about this problem.  \n",
        "<br>\n",
        "If you want to experiment **underfitting**, set `test_overfitting` to `False` and  increase the value of `cv_precentage` from its default value to `0.95`. This will significantly increase the size of the **cross validation split** at detriment of the **train split**, which will be strongly reduced.  In this condition, the model has so few data available for training that is not able to learn at all. <br> This is similar to the condition that students face when the explanation provided by tutor is so poor that they are not even able to reproduce the exercises done during the lesson. <br> I hope this is not the case for you :)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zlw-38ac73tA"
      },
      "outputs": [],
      "source": [
        "# CV percentage (ignored if test_overfitting == True)\n",
        "cv_percentage=0.1666540669186616"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gphZFCT8gSf"
      },
      "source": [
        "We are now randomly splitting `train_MNIST` into `train_MNIST` and `cv_MNIST` with the requested percentages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ble4xYM9CU7q"
      },
      "outputs": [],
      "source": [
        "# Stacking tuples into a single list\n",
        "train_MNIST_list = []\n",
        "train_MNIST_list = [train_MNIST_list + list(x) for x in train_MNIST]\n",
        "\n",
        "# Creating random splits with the requested percentage\n",
        "train_idx, valid_idx = train_test_split(list(range(60000)), test_size=(cv_percentage))\n",
        "# Creating Valid\n",
        "cv_MNIST = [train_MNIST_list[x] for x in valid_idx]\n",
        "# Creating Train\n",
        "train_MNIST = [train_MNIST_list[x] for x in train_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIu2eewv0qsH"
      },
      "source": [
        "## 3 - Creating a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuWZYZhV9pg6"
      },
      "source": [
        "We now create a custom **Convolutional Neural Network (CNN)**. The network is created and designed **from scratch** for the sake of providing an example. <br> However, in real life, this might not be the best idea. [Here](https://paperswithcode.com/sota/image-classification-on-imagenet) you can see the benchmark among different models on the [ImageNet](https://www.image-net.org/), a very complex benchmark dataset for image classification. <br>\n",
        "In general, it is also possible to start from a **pretrained model**, i.e., a model that was already trained on another dataset (typically, `ImageNet`) to leverage preliminary `knowledge` that a network acquired on another dataset, which can be particularly useful when few training examples are available. <br> In our example, the network is custom and not pretrained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7C5_yanr1oHp"
      },
      "outputs": [],
      "source": [
        "class CNNNet(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(CNNNet, self).__init__()\n",
        "        # Convolutional layer (1 input channel, 25 output-channels, 5x5 kernels)\n",
        "        self.conv1 = nn.Conv2d(1, 25, kernel_size=5)\n",
        "        # Convolutional layer (25 input channel, 100 output-channels, 5x5 k.)\n",
        "        self.conv2 = nn.Conv2d(25, 100, kernel_size=5)\n",
        "        # Dropout - This layer is used to remove unnecessary neurons.\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        # Convolutional layer (100 input channel, 25 output-channels, 3x3 k.)\n",
        "        self.conv3 = nn.Conv2d(100, 25, kernel_size=3)\n",
        "        # Average pooling - Spatial average of the pixels\n",
        "        self.avg_pool = torch.nn.AvgPool2d(2)\n",
        "        # Fully connected layer\n",
        "        self.fc2 = nn.Linear(25, 10)\n",
        "\n",
        "    # Describes how the network behave\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.conv1(x)\n",
        "        # Pooling layers - selects the max between 2 neurons\n",
        "        y = F.max_pool2d(y,2)\n",
        "        # Relu - Activation function\n",
        "        y = F.relu(y)\n",
        "        # Convolutional layer (10 input channel, 50 output-channels, 5x5 k.)\n",
        "        y = self.conv2(y)\n",
        "        # Dropout\n",
        "        y = self.conv2_drop(y)\n",
        "        # Pooling layers - selects the max between 2 neurons\n",
        "        y = F.max_pool2d(y,2)\n",
        "        # Relu - Activation function\n",
        "        y = F.relu(y)\n",
        "        # Convolutional layer\n",
        "        y = self.conv3(y)\n",
        "        # Relu - Activation function\n",
        "        y = F.relu(y)\n",
        "        # Convolutional layer\n",
        "        y = self.avg_pool(y)\n",
        "        # Fully connected layer\n",
        "        # Squeeze is needed because fc2 requires\n",
        "        # a 2D tensor.\n",
        "        y = self.fc2(y.squeeze(-1).squeeze(-1))\n",
        "        # Applying Softmax\n",
        "        p_c = F.log_softmax(y, dim=1)\n",
        "        return p_c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKEsY4ApzRHD"
      },
      "source": [
        "We create an instance of our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "emzBWMd_-4u1"
      },
      "outputs": [],
      "source": [
        "model = CNNNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZVvxHJj_DSy"
      },
      "source": [
        "## 4 - Preparing for training - Setting Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWboeHcHc1GO"
      },
      "source": [
        "Weights and biases in a model are called **parameters**, which are actually learned by the model during training. However, there are other tunable variables such as the number of neurons in a layer, the size of a kernel, and others that are not directly learned by the network but whose values can affect training. Such variables are called **hyperparameters**. Some of the hyperparameters, such as the number of epochs and learning rate, will be now explained and set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpKYC9gh_XDR"
      },
      "source": [
        "### 4.1 - Setting Cross-entropy loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzmu-fek_Zbc"
      },
      "source": [
        "To train the model, we use [Categorical Cross-entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) loss, as specified by the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sAJYfyXO_Ree"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPtLQZwe_zlw"
      },
      "source": [
        "4.2 - Selecting number of epochs and batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Biskgzvk_2Py"
      },
      "source": [
        "We are going to select:\n",
        "* `number of epochs`: number of epochs specify how many times the entire dataset is seen by the model during training. Increasing the number of epochs typically leads the model to learn better the training dataset (i.e., to lower loss values in the training set). However, this is not necessarily a positive thing given the risk of **overfitting** the dataset. **Try to play with the number of epochs to see the impact in training.**\n",
        "\n",
        "* `batch size`: In the lesson slides, we have calculated the loss over the entire dataset (whose number is called `N`). When the input data are images, it is typically impossible to provide the entire dataset as input to the model in a single pass because of GPU/CPU memory limitations. Therefore, each epoch is therefore divided into a certain number of `iterations`, during which the loss function is calculated on a reduced number of samples (`batch`). The `batch size` is, of course, the size of batches. Typically, the `batch size` is a power of 2 to allow for better computational performances (better optimization to computing hardware). <br> The choice on the `batch size` typically influences both the training time and the model accuracy.  **Higher batch sizes** allow for:\n",
        "    *  **higher computational performances**: because of the higher parallization (as far as they fit into your hardware memory and your hardware can profit of it).\n",
        "    *  **lower convergence** (so, not necessarily a faster training in the end):  high batch size means lower number of batches and, therefore, lower number of updates.\n",
        "    *  **more robust toward noise and fluctuations**: because the loss is evaluated on a higher number of samples, so the averaging effect is stronger.\n",
        "    *  **higher overfitting**: the noise due to batching acts as a regularization agent during the training reducing overfitting. Such noise is reduced because of the stronger averaging effect, diminishing the regularization effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VjIhY9K6_geQ"
      },
      "outputs": [],
      "source": [
        "# Number of epochs\n",
        "n_epochs = 10\n",
        "# Batch size\n",
        "batch_size=32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM1mEs3ZAtlx"
      },
      "source": [
        "### 4.2 - Create dataloaders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsn-c15wAy1f"
      },
      "source": [
        "To break your dataset into `batch` of size `batch_size`, PyTorch provides a construct called [data loader](https://www.educative.io/answers/what-is-pytorch-dataloader).<br> As previously mentioned, this is useful to ensure that your dataset will fit into your memory and to create a \"stochastic\" implementation of gradient descent. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6RiCKFMPAyLe"
      },
      "outputs": [],
      "source": [
        "# Train loader\n",
        "train_loader = DataLoader(train_MNIST, batch_size=batch_size, pin_memory=False, shuffle=True)\n",
        "# Cross validation data loader\n",
        "valid_loader = DataLoader(cv_MNIST, batch_size=batch_size, pin_memory=False, shuffle=True)\n",
        "# Test data loader\n",
        "test_loader = DataLoader(test_MNIST, batch_size=batch_size, pin_memory=False, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7zTkwuoHNOX"
      },
      "source": [
        "### 4.3 -  Selecting Training optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRRMv_RdHaY6"
      },
      "source": [
        "To train the model we are now selecting [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) optimizer, which means `Stochastic Gradient Descent`. <br> You can think of optimizers as rules that specify how to update parameters. Different optimers lead to different weights for the same model, data and loss function. There is not a specific rule on how to select an optimizer. You can find more information on optimizers [here](https://pytorch.org/docs/stable/optim.html) is popular for its performance/memory-efficiency trade-offs. <br> The **learning rate** (`lr`) is a scale-factor hyperparameter that determines the step-size in updating your model parameters. During training, you want to minimize the loss function, which means reaching the minimum with a fixed step size. The **learning rate** is the size of your step, If your step is too big, you might end-up missing the minimum and jumping over the minimum. However, if your step is too small, your training time will be very long and the risk to get stuck in local minima is very high."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pUDcRiCtHHB4"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSL7vH-WIO3l"
      },
      "source": [
        "## 5 - Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BItaHAzsIR-m"
      },
      "source": [
        "In the next cell, we start the training of our model.\n",
        "During the training we log the `train_loss` and the `evaluation_loss` to be able to monitor the outcome of training after training. <br>  Training of deep neural networks is typically  a slow processes. Because of that, it is possible to skip the training process by loading the trained model and the values of the loss from files to save you some time. To this aim, set the flag `skip_train` to `True` in the next cell. <br> However, it could be useful to you to try change some of the parameters (e.g., `cv_percentage`, `nr_of_epochs`) to see their impact on training results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w7MnQ-b73Ein"
      },
      "outputs": [],
      "source": [
        "skip_training=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1ntScsg3B_9"
      },
      "source": [
        "If you have selected `skip_training=False`, training will be started. In addition to the loss values, we also print the `accuracy` on `train` and `cross_validation`. You should see the **losses decreasing** and **accuracies increasing** (as a trend) over the various epochs. <br> Please, notice that we are not trying to prevent overfitting in any way (except for Dropout layers). <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMbyG13MISNm",
        "outputId": "458f408d-7e93-451a-8b2b-e72fb0ffee6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   0%|          | 1/1563 [00:01<33:32,  1.29s/it]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 40/1563 [00:01<00:38, 39.54it/s]\u001b[A\n",
            "Training - Iterations::   5%|▌         | 79/1563 [00:01<00:17, 83.06it/s]\u001b[A\n",
            "Training - Iterations::   7%|▋         | 113/1563 [00:01<00:11, 121.64it/s]\u001b[A\n",
            "Training - Iterations::  10%|▉         | 153/1563 [00:01<00:08, 170.55it/s]\u001b[A\n",
            "Training - Iterations::  12%|█▏        | 194/1563 [00:01<00:06, 218.36it/s]\u001b[A\n",
            "Training - Iterations::  15%|█▌        | 235/1563 [00:01<00:05, 260.69it/s]\u001b[A\n",
            "Training - Iterations::  18%|█▊        | 277/1563 [00:01<00:04, 297.42it/s]\u001b[A\n",
            "Training - Iterations::  20%|██        | 320/1563 [00:02<00:03, 329.79it/s]\u001b[A\n",
            "Training - Iterations::  23%|██▎       | 361/1563 [00:02<00:03, 350.24it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 403/1563 [00:02<00:03, 367.27it/s]\u001b[A\n",
            "Training - Iterations::  28%|██▊       | 444/1563 [00:02<00:03, 371.60it/s]\u001b[A\n",
            "Training - Iterations::  31%|███       | 484/1563 [00:02<00:02, 379.07it/s]\u001b[A\n",
            "Training - Iterations::  34%|███▎      | 524/1563 [00:02<00:02, 354.13it/s]\u001b[A\n",
            "Training - Iterations::  36%|███▌      | 562/1563 [00:02<00:02, 353.13it/s]\u001b[A\n",
            "Training - Iterations::  39%|███▊      | 602/1563 [00:02<00:02, 365.68it/s]\u001b[A\n",
            "Training - Iterations::  41%|████      | 642/1563 [00:02<00:02, 373.53it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▎     | 683/1563 [00:03<00:02, 381.74it/s]\u001b[A\n",
            "Training - Iterations::  46%|████▋     | 723/1563 [00:03<00:02, 385.42it/s]\u001b[A\n",
            "Training - Iterations::  49%|████▉     | 764/1563 [00:03<00:02, 390.23it/s]\u001b[A\n",
            "Training - Iterations::  51%|█████▏    | 804/1563 [00:03<00:01, 387.56it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▍    | 844/1563 [00:03<00:01, 389.22it/s]\u001b[A\n",
            "Training - Iterations::  57%|█████▋    | 884/1563 [00:03<00:01, 391.17it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▉    | 924/1563 [00:03<00:01, 361.90it/s]\u001b[A\n",
            "Training - Iterations::  62%|██████▏   | 965/1563 [00:03<00:01, 373.26it/s]\u001b[A\n",
            "Training - Iterations::  64%|██████▍   | 1007/1563 [00:03<00:01, 386.09it/s]\u001b[A\n",
            "Training - Iterations::  67%|██████▋   | 1048/1563 [00:03<00:01, 392.87it/s]\u001b[A\n",
            "Training - Iterations::  70%|██████▉   | 1090/1563 [00:04<00:01, 400.52it/s]\u001b[A\n",
            "Training - Iterations::  72%|███████▏  | 1131/1563 [00:04<00:01, 403.08it/s]\u001b[A\n",
            "Training - Iterations::  75%|███████▌  | 1173/1563 [00:04<00:00, 405.22it/s]\u001b[A\n",
            "Training - Iterations::  78%|███████▊  | 1214/1563 [00:04<00:00, 404.05it/s]\u001b[A\n",
            "Training - Iterations::  80%|████████  | 1255/1563 [00:04<00:00, 400.98it/s]\u001b[A\n",
            "Training - Iterations::  83%|████████▎ | 1296/1563 [00:04<00:00, 389.89it/s]\u001b[A\n",
            "Training - Iterations::  85%|████████▌ | 1336/1563 [00:04<00:00, 369.96it/s]\u001b[A\n",
            "Training - Iterations::  88%|████████▊ | 1374/1563 [00:04<00:00, 370.00it/s]\u001b[A\n",
            "Training - Iterations::  91%|█████████ | 1415/1563 [00:04<00:00, 380.77it/s]\u001b[A\n",
            "Training - Iterations::  93%|█████████▎| 1457/1563 [00:05<00:00, 389.88it/s]\u001b[A\n",
            "Training - Iterations::  96%|█████████▌| 1497/1563 [00:05<00:00, 374.30it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:05<00:00, 286.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  24%|██▍       | 75/313 [00:00<00:00, 742.74it/s]\u001b[A\n",
            "Evaluation - Iteration::  48%|████▊     | 150/313 [00:00<00:00, 675.93it/s]\u001b[A\n",
            "Evaluation - Iteration::  70%|██████▉   | 218/313 [00:00<00:00, 633.75it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 687.74it/s]\n",
            "Epochs:  10%|█         | 1/10 [00:05<00:53,  5.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 0\n",
            "\u001b[1mTrain loss\u001b[1m: 2.306055784225464.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 13.152.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 2.2585699558258057.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 10.66.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   2%|▏         | 33/1563 [00:00<00:04, 321.73it/s]\u001b[A\n",
            "Training - Iterations::   4%|▍         | 66/1563 [00:00<00:04, 303.16it/s]\u001b[A\n",
            "Training - Iterations::   6%|▋         | 99/1563 [00:00<00:04, 313.96it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 131/1563 [00:00<00:04, 313.03it/s]\u001b[A\n",
            "Training - Iterations::  11%|█         | 166/1563 [00:00<00:04, 325.33it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 201/1563 [00:00<00:04, 331.80it/s]\u001b[A\n",
            "Training - Iterations::  15%|█▌        | 235/1563 [00:00<00:04, 288.46it/s]\u001b[A\n",
            "Training - Iterations::  17%|█▋        | 265/1563 [00:00<00:04, 277.32it/s]\u001b[A\n",
            "Training - Iterations::  19%|█▉        | 299/1563 [00:00<00:04, 294.11it/s]\u001b[A\n",
            "Training - Iterations::  21%|██        | 330/1563 [00:01<00:04, 292.44it/s]\u001b[A\n",
            "Training - Iterations::  23%|██▎       | 360/1563 [00:01<00:04, 291.13it/s]\u001b[A\n",
            "Training - Iterations::  25%|██▍       | 390/1563 [00:01<00:04, 291.90it/s]\u001b[A\n",
            "Training - Iterations::  27%|██▋       | 422/1563 [00:01<00:03, 298.74it/s]\u001b[A\n",
            "Training - Iterations::  29%|██▉       | 455/1563 [00:01<00:03, 307.59it/s]\u001b[A\n",
            "Training - Iterations::  31%|███       | 486/1563 [00:01<00:03, 305.98it/s]\u001b[A\n",
            "Training - Iterations::  33%|███▎      | 517/1563 [00:01<00:03, 301.27it/s]\u001b[A\n",
            "Training - Iterations::  35%|███▌      | 548/1563 [00:01<00:03, 300.48it/s]\u001b[A\n",
            "Training - Iterations::  37%|███▋      | 579/1563 [00:01<00:03, 299.75it/s]\u001b[A\n",
            "Training - Iterations::  39%|███▉      | 611/1563 [00:02<00:03, 303.10it/s]\u001b[A\n",
            "Training - Iterations::  41%|████      | 644/1563 [00:02<00:02, 308.39it/s]\u001b[A\n",
            "Training - Iterations::  43%|████▎     | 675/1563 [00:02<00:02, 304.71it/s]\u001b[A\n",
            "Training - Iterations::  45%|████▌     | 706/1563 [00:02<00:02, 302.28it/s]\u001b[A\n",
            "Training - Iterations::  48%|████▊     | 746/1563 [00:02<00:02, 329.33it/s]\u001b[A\n",
            "Training - Iterations::  50%|█████     | 785/1563 [00:02<00:02, 345.26it/s]\u001b[A\n",
            "Training - Iterations::  53%|█████▎    | 825/1563 [00:02<00:02, 360.73it/s]\u001b[A\n",
            "Training - Iterations::  55%|█████▌    | 862/1563 [00:02<00:01, 352.09it/s]\u001b[A\n",
            "Training - Iterations::  58%|█████▊    | 902/1563 [00:02<00:01, 365.73it/s]\u001b[A\n",
            "Training - Iterations::  60%|██████    | 942/1563 [00:02<00:01, 373.40it/s]\u001b[A\n",
            "Training - Iterations::  63%|██████▎   | 984/1563 [00:03<00:01, 385.32it/s]\u001b[A\n",
            "Training - Iterations::  66%|██████▌   | 1025/1563 [00:03<00:01, 390.28it/s]\u001b[A\n",
            "Training - Iterations::  68%|██████▊   | 1067/1563 [00:03<00:01, 397.12it/s]\u001b[A\n",
            "Training - Iterations::  71%|███████   | 1107/1563 [00:03<00:01, 397.73it/s]\u001b[A\n",
            "Training - Iterations::  73%|███████▎  | 1147/1563 [00:03<00:01, 395.78it/s]\u001b[A\n",
            "Training - Iterations::  76%|███████▌  | 1187/1563 [00:03<00:00, 388.92it/s]\u001b[A\n",
            "Training - Iterations::  78%|███████▊  | 1226/1563 [00:03<00:00, 379.01it/s]\u001b[A\n",
            "Training - Iterations::  81%|████████  | 1264/1563 [00:03<00:00, 364.07it/s]\u001b[A\n",
            "Training - Iterations::  83%|████████▎ | 1305/1563 [00:03<00:00, 376.48it/s]\u001b[A\n",
            "Training - Iterations::  86%|████████▌ | 1343/1563 [00:04<00:00, 370.27it/s]\u001b[A\n",
            "Training - Iterations::  89%|████████▊ | 1384/1563 [00:04<00:00, 381.26it/s]\u001b[A\n",
            "Training - Iterations::  91%|█████████ | 1423/1563 [00:04<00:00, 383.77it/s]\u001b[A\n",
            "Training - Iterations::  94%|█████████▎| 1462/1563 [00:04<00:00, 384.68it/s]\u001b[A\n",
            "Training - Iterations::  96%|█████████▌| 1501/1563 [00:04<00:00, 386.14it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 342.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  26%|██▌       | 80/313 [00:00<00:00, 799.46it/s]\u001b[A\n",
            "Evaluation - Iteration::  51%|█████     | 160/313 [00:00<00:00, 789.56it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 817.68it/s]\n",
            "Epochs:  20%|██        | 2/10 [00:10<00:42,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 1\n",
            "\u001b[1mTrain loss\u001b[1m: 2.2673799991607666.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 17.774.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 2.260172128677368.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 28.449999999999996.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 43/1563 [00:00<00:03, 421.82it/s]\u001b[A\n",
            "Training - Iterations::   6%|▌         | 86/1563 [00:00<00:03, 407.22it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 127/1563 [00:00<00:03, 405.66it/s]\u001b[A\n",
            "Training - Iterations::  11%|█         | 168/1563 [00:00<00:03, 399.65it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 210/1563 [00:00<00:03, 404.85it/s]\u001b[A\n",
            "Training - Iterations::  16%|█▌        | 251/1563 [00:00<00:03, 397.83it/s]\u001b[A\n",
            "Training - Iterations::  19%|█▊        | 291/1563 [00:00<00:03, 386.42it/s]\u001b[A\n",
            "Training - Iterations::  21%|██        | 330/1563 [00:00<00:03, 373.19it/s]\u001b[A\n",
            "Training - Iterations::  24%|██▎       | 370/1563 [00:00<00:03, 379.99it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 409/1563 [00:01<00:03, 381.78it/s]\u001b[A\n",
            "Training - Iterations::  29%|██▉       | 450/1563 [00:01<00:02, 388.86it/s]\u001b[A\n",
            "Training - Iterations::  31%|███▏      | 492/1563 [00:01<00:02, 395.64it/s]\u001b[A\n",
            "Training - Iterations::  34%|███▍      | 532/1563 [00:01<00:02, 395.37it/s]\u001b[A\n",
            "Training - Iterations::  37%|███▋      | 572/1563 [00:01<00:02, 395.44it/s]\u001b[A\n",
            "Training - Iterations::  39%|███▉      | 612/1563 [00:01<00:02, 395.91it/s]\u001b[A\n",
            "Training - Iterations::  42%|████▏     | 652/1563 [00:01<00:02, 396.97it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▍     | 692/1563 [00:01<00:02, 369.71it/s]\u001b[A\n",
            "Training - Iterations::  47%|████▋     | 730/1563 [00:01<00:02, 370.45it/s]\u001b[A\n",
            "Training - Iterations::  49%|████▉     | 770/1563 [00:01<00:02, 377.16it/s]\u001b[A\n",
            "Training - Iterations::  52%|█████▏    | 808/1563 [00:02<00:02, 376.23it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▍    | 848/1563 [00:02<00:01, 382.21it/s]\u001b[A\n",
            "Training - Iterations::  57%|█████▋    | 889/1563 [00:02<00:01, 388.62it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▉    | 928/1563 [00:02<00:01, 386.57it/s]\u001b[A\n",
            "Training - Iterations::  62%|██████▏   | 968/1563 [00:02<00:01, 389.68it/s]\u001b[A\n",
            "Training - Iterations::  64%|██████▍   | 1008/1563 [00:02<00:01, 389.20it/s]\u001b[A\n",
            "Training - Iterations::  67%|██████▋   | 1047/1563 [00:02<00:01, 384.08it/s]\u001b[A\n",
            "Training - Iterations::  69%|██████▉   | 1086/1563 [00:02<00:01, 369.78it/s]\u001b[A\n",
            "Training - Iterations::  72%|███████▏  | 1127/1563 [00:02<00:01, 379.50it/s]\u001b[A\n",
            "Training - Iterations::  75%|███████▍  | 1167/1563 [00:03<00:01, 383.50it/s]\u001b[A\n",
            "Training - Iterations::  77%|███████▋  | 1206/1563 [00:03<00:00, 382.95it/s]\u001b[A\n",
            "Training - Iterations::  80%|███████▉  | 1245/1563 [00:03<00:00, 384.92it/s]\u001b[A\n",
            "Training - Iterations::  82%|████████▏ | 1286/1563 [00:03<00:00, 390.28it/s]\u001b[A\n",
            "Training - Iterations::  85%|████████▍ | 1326/1563 [00:03<00:00, 391.77it/s]\u001b[A\n",
            "Training - Iterations::  87%|████████▋ | 1367/1563 [00:03<00:00, 396.98it/s]\u001b[A\n",
            "Training - Iterations::  90%|█████████ | 1407/1563 [00:03<00:00, 395.18it/s]\u001b[A\n",
            "Training - Iterations::  93%|█████████▎| 1447/1563 [00:03<00:00, 382.89it/s]\u001b[A\n",
            "Training - Iterations::  95%|█████████▌| 1486/1563 [00:03<00:00, 369.82it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 386.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 2.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  26%|██▌       | 80/313 [00:00<00:00, 791.59it/s]\u001b[A\n",
            "Evaluation - Iteration::  58%|█████▊    | 180/313 [00:00<00:00, 913.46it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 910.92it/s]\n",
            "Epochs:  30%|███       | 3/10 [00:15<00:34,  4.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 2\n",
            "\u001b[1mTrain loss\u001b[1m: 2.2145566940307617.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 23.198.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 2.236212730407715.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 33.26.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 41/1563 [00:00<00:03, 406.60it/s]\u001b[A\n",
            "Training - Iterations::   5%|▌         | 82/1563 [00:00<00:03, 402.04it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 123/1563 [00:00<00:03, 385.98it/s]\u001b[A\n",
            "Training - Iterations::  10%|█         | 162/1563 [00:00<00:03, 353.42it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 203/1563 [00:00<00:03, 369.78it/s]\u001b[A\n",
            "Training - Iterations::  15%|█▌        | 242/1563 [00:00<00:03, 374.75it/s]\u001b[A\n",
            "Training - Iterations::  18%|█▊        | 280/1563 [00:00<00:03, 374.70it/s]\u001b[A\n",
            "Training - Iterations::  20%|██        | 320/1563 [00:00<00:03, 381.42it/s]\u001b[A\n",
            "Training - Iterations::  23%|██▎       | 360/1563 [00:00<00:03, 386.18it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 399/1563 [00:01<00:03, 386.25it/s]\u001b[A\n",
            "Training - Iterations::  28%|██▊       | 440/1563 [00:01<00:02, 391.83it/s]\u001b[A\n",
            "Training - Iterations::  31%|███       | 480/1563 [00:01<00:02, 387.85it/s]\u001b[A\n",
            "Training - Iterations::  33%|███▎      | 519/1563 [00:01<00:02, 365.75it/s]\u001b[A\n",
            "Training - Iterations::  36%|███▌      | 556/1563 [00:01<00:02, 361.77it/s]\u001b[A\n",
            "Training - Iterations::  38%|███▊      | 597/1563 [00:01<00:02, 374.03it/s]\u001b[A\n",
            "Training - Iterations::  41%|████      | 638/1563 [00:01<00:02, 383.96it/s]\u001b[A\n",
            "Training - Iterations::  43%|████▎     | 677/1563 [00:01<00:02, 382.75it/s]\u001b[A\n",
            "Training - Iterations::  46%|████▌     | 718/1563 [00:01<00:02, 388.84it/s]\u001b[A\n",
            "Training - Iterations::  49%|████▊     | 760/1563 [00:01<00:02, 397.95it/s]\u001b[A\n",
            "Training - Iterations::  51%|█████     | 801/1563 [00:02<00:01, 399.05it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▍    | 841/1563 [00:02<00:01, 395.07it/s]\u001b[A\n",
            "Training - Iterations::  56%|█████▋    | 881/1563 [00:02<00:01, 389.82it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▉    | 921/1563 [00:02<00:01, 373.01it/s]\u001b[A\n",
            "Training - Iterations::  61%|██████▏   | 960/1563 [00:02<00:01, 376.02it/s]\u001b[A\n",
            "Training - Iterations::  64%|██████▍   | 1000/1563 [00:02<00:01, 381.59it/s]\u001b[A\n",
            "Training - Iterations::  67%|██████▋   | 1042/1563 [00:02<00:01, 390.90it/s]\u001b[A\n",
            "Training - Iterations::  69%|██████▉   | 1082/1563 [00:02<00:01, 386.10it/s]\u001b[A\n",
            "Training - Iterations::  72%|███████▏  | 1123/1563 [00:02<00:01, 391.41it/s]\u001b[A\n",
            "Training - Iterations::  74%|███████▍  | 1163/1563 [00:03<00:01, 363.31it/s]\u001b[A\n",
            "Training - Iterations::  77%|███████▋  | 1200/1563 [00:03<00:01, 349.10it/s]\u001b[A\n",
            "Training - Iterations::  79%|███████▉  | 1236/1563 [00:03<00:00, 333.65it/s]\u001b[A\n",
            "Training - Iterations::  81%|████████▏ | 1270/1563 [00:03<00:00, 318.47it/s]\u001b[A\n",
            "Training - Iterations::  83%|████████▎ | 1303/1563 [00:03<00:00, 320.08it/s]\u001b[A\n",
            "Training - Iterations::  86%|████████▌ | 1339/1563 [00:03<00:00, 328.50it/s]\u001b[A\n",
            "Training - Iterations::  88%|████████▊ | 1373/1563 [00:03<00:00, 322.98it/s]\u001b[A\n",
            "Training - Iterations::  90%|████████▉ | 1406/1563 [00:03<00:00, 315.71it/s]\u001b[A\n",
            "Training - Iterations::  92%|█████████▏| 1438/1563 [00:03<00:00, 316.90it/s]\u001b[A\n",
            "Training - Iterations::  94%|█████████▍| 1475/1563 [00:04<00:00, 331.10it/s]\u001b[A\n",
            "Training - Iterations::  97%|█████████▋| 1511/1563 [00:04<00:00, 337.14it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 361.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 3.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  19%|█▉        | 60/313 [00:00<00:00, 589.83it/s]\u001b[A\n",
            "Evaluation - Iteration::  39%|███▉      | 122/313 [00:00<00:00, 603.52it/s]\u001b[A\n",
            "Evaluation - Iteration::  63%|██████▎   | 198/313 [00:00<00:00, 673.03it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 669.00it/s]\n",
            "Epochs:  40%|████      | 4/10 [00:20<00:29,  4.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 3\n",
            "\u001b[1mTrain loss\u001b[1m: 2.2261905670166016.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 28.548000000000002.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 2.133038282394409.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 38.54.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   2%|▏         | 28/1563 [00:00<00:05, 279.43it/s]\u001b[A\n",
            "Training - Iterations::   4%|▎         | 56/1563 [00:00<00:05, 279.44it/s]\u001b[A\n",
            "Training - Iterations::   6%|▌         | 87/1563 [00:00<00:05, 289.51it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 118/1563 [00:00<00:04, 297.04it/s]\u001b[A\n",
            "Training - Iterations::   9%|▉         | 148/1563 [00:00<00:04, 293.45it/s]\u001b[A\n",
            "Training - Iterations::  11%|█▏        | 178/1563 [00:00<00:04, 280.90it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 208/1563 [00:00<00:04, 285.77it/s]\u001b[A\n",
            "Training - Iterations::  15%|█▌        | 241/1563 [00:00<00:04, 296.61it/s]\u001b[A\n",
            "Training - Iterations::  17%|█▋        | 272/1563 [00:00<00:04, 298.14it/s]\u001b[A\n",
            "Training - Iterations::  19%|█▉        | 302/1563 [00:01<00:04, 297.31it/s]\u001b[A\n",
            "Training - Iterations::  21%|██▏       | 335/1563 [00:01<00:04, 306.68it/s]\u001b[A\n",
            "Training - Iterations::  24%|██▍       | 377/1563 [00:01<00:03, 338.73it/s]\u001b[A\n",
            "Training - Iterations::  27%|██▋       | 415/1563 [00:01<00:03, 349.14it/s]\u001b[A\n",
            "Training - Iterations::  29%|██▉       | 457/1563 [00:01<00:03, 367.97it/s]\u001b[A\n",
            "Training - Iterations::  32%|███▏      | 494/1563 [00:01<00:03, 355.62it/s]\u001b[A\n",
            "Training - Iterations::  34%|███▍      | 533/1563 [00:01<00:02, 364.17it/s]\u001b[A\n",
            "Training - Iterations::  37%|███▋      | 573/1563 [00:01<00:02, 372.33it/s]\u001b[A\n",
            "Training - Iterations::  39%|███▉      | 614/1563 [00:01<00:02, 382.93it/s]\u001b[A\n",
            "Training - Iterations::  42%|████▏     | 653/1563 [00:01<00:02, 384.05it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▍     | 694/1563 [00:02<00:02, 389.20it/s]\u001b[A\n",
            "Training - Iterations::  47%|████▋     | 733/1563 [00:02<00:02, 379.93it/s]\u001b[A\n",
            "Training - Iterations::  50%|████▉     | 774/1563 [00:02<00:02, 384.50it/s]\u001b[A\n",
            "Training - Iterations::  52%|█████▏    | 814/1563 [00:02<00:01, 387.38it/s]\u001b[A\n",
            "Training - Iterations::  55%|█████▍    | 853/1563 [00:02<00:01, 379.86it/s]\u001b[A\n",
            "Training - Iterations::  57%|█████▋    | 892/1563 [00:02<00:01, 364.75it/s]\u001b[A\n",
            "Training - Iterations::  60%|█████▉    | 930/1563 [00:02<00:01, 368.50it/s]\u001b[A\n",
            "Training - Iterations::  62%|██████▏   | 971/1563 [00:02<00:01, 378.94it/s]\u001b[A\n",
            "Training - Iterations::  65%|██████▍   | 1013/1563 [00:02<00:01, 390.29it/s]\u001b[A\n",
            "Training - Iterations::  67%|██████▋   | 1055/1563 [00:03<00:01, 396.23it/s]\u001b[A\n",
            "Training - Iterations::  70%|███████   | 1097/1563 [00:03<00:01, 402.49it/s]\u001b[A\n",
            "Training - Iterations::  73%|███████▎  | 1138/1563 [00:03<00:01, 395.74it/s]\u001b[A\n",
            "Training - Iterations::  76%|███████▌  | 1181/1563 [00:03<00:00, 403.99it/s]\u001b[A\n",
            "Training - Iterations::  78%|███████▊  | 1222/1563 [00:03<00:00, 400.74it/s]\u001b[A\n",
            "Training - Iterations::  81%|████████  | 1263/1563 [00:03<00:00, 387.01it/s]\u001b[A\n",
            "Training - Iterations::  83%|████████▎ | 1302/1563 [00:03<00:00, 379.13it/s]\u001b[A\n",
            "Training - Iterations::  86%|████████▌ | 1343/1563 [00:03<00:00, 386.63it/s]\u001b[A\n",
            "Training - Iterations::  89%|████████▊ | 1384/1563 [00:03<00:00, 391.38it/s]\u001b[A\n",
            "Training - Iterations::  91%|█████████▏| 1427/1563 [00:03<00:00, 401.01it/s]\u001b[A\n",
            "Training - Iterations::  94%|█████████▍| 1469/1563 [00:04<00:00, 404.25it/s]\u001b[A\n",
            "Training - Iterations::  97%|█████████▋| 1511/1563 [00:04<00:00, 407.12it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 364.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 4.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  33%|███▎      | 104/313 [00:00<00:00, 1027.73it/s]\u001b[A\n",
            "Evaluation - Iteration::  66%|██████▌   | 207/313 [00:00<00:00, 941.65it/s] \u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 895.99it/s]\n",
            "Epochs:  50%|█████     | 5/10 [00:24<00:24,  4.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 4\n",
            "\u001b[1mTrain loss\u001b[1m: 2.122631549835205.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 35.144.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 2.0817453861236572.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 46.47.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 42/1563 [00:00<00:03, 411.97it/s]\u001b[A\n",
            "Training - Iterations::   5%|▌         | 84/1563 [00:00<00:03, 403.66it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 126/1563 [00:00<00:03, 407.30it/s]\u001b[A\n",
            "Training - Iterations::  11%|█         | 167/1563 [00:00<00:03, 389.10it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 207/1563 [00:00<00:03, 383.41it/s]\u001b[A\n",
            "Training - Iterations::  16%|█▌        | 246/1563 [00:00<00:03, 381.36it/s]\u001b[A\n",
            "Training - Iterations::  18%|█▊        | 288/1563 [00:00<00:03, 389.79it/s]\u001b[A\n",
            "Training - Iterations::  21%|██        | 328/1563 [00:00<00:03, 376.09it/s]\u001b[A\n",
            "Training - Iterations::  23%|██▎       | 366/1563 [00:00<00:03, 362.61it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 407/1563 [00:01<00:03, 375.02it/s]\u001b[A\n",
            "Training - Iterations::  29%|██▊       | 448/1563 [00:01<00:02, 382.86it/s]\u001b[A\n",
            "Training - Iterations::  31%|███▏      | 490/1563 [00:01<00:02, 391.64it/s]\u001b[A\n",
            "Training - Iterations::  34%|███▍      | 531/1563 [00:01<00:02, 395.45it/s]\u001b[A\n",
            "Training - Iterations::  37%|███▋      | 572/1563 [00:01<00:02, 397.12it/s]\u001b[A\n",
            "Training - Iterations::  39%|███▉      | 612/1563 [00:01<00:02, 392.01it/s]\u001b[A\n",
            "Training - Iterations::  42%|████▏     | 653/1563 [00:01<00:02, 394.75it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▍     | 693/1563 [00:01<00:02, 394.47it/s]\u001b[A\n",
            "Training - Iterations::  47%|████▋     | 733/1563 [00:01<00:02, 374.62it/s]\u001b[A\n",
            "Training - Iterations::  49%|████▉     | 771/1563 [00:02<00:02, 374.70it/s]\u001b[A\n",
            "Training - Iterations::  52%|█████▏    | 809/1563 [00:02<00:02, 368.95it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▍    | 848/1563 [00:02<00:01, 373.56it/s]\u001b[A\n",
            "Training - Iterations::  57%|█████▋    | 887/1563 [00:02<00:01, 378.16it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▉    | 926/1563 [00:02<00:01, 381.61it/s]\u001b[A\n",
            "Training - Iterations::  62%|██████▏   | 966/1563 [00:02<00:01, 385.26it/s]\u001b[A\n",
            "Training - Iterations::  64%|██████▍   | 1005/1563 [00:02<00:01, 377.24it/s]\u001b[A\n",
            "Training - Iterations::  67%|██████▋   | 1046/1563 [00:02<00:01, 386.43it/s]\u001b[A\n",
            "Training - Iterations::  69%|██████▉   | 1085/1563 [00:02<00:01, 384.29it/s]\u001b[A\n",
            "Training - Iterations::  72%|███████▏  | 1124/1563 [00:02<00:01, 367.17it/s]\u001b[A\n",
            "Training - Iterations::  74%|███████▍  | 1164/1563 [00:03<00:01, 376.21it/s]\u001b[A\n",
            "Training - Iterations::  77%|███████▋  | 1205/1563 [00:03<00:00, 385.39it/s]\u001b[A\n",
            "Training - Iterations::  80%|███████▉  | 1245/1563 [00:03<00:00, 388.33it/s]\u001b[A\n",
            "Training - Iterations::  82%|████████▏ | 1287/1563 [00:03<00:00, 395.09it/s]\u001b[A\n",
            "Training - Iterations::  85%|████████▍ | 1327/1563 [00:03<00:00, 394.52it/s]\u001b[A\n",
            "Training - Iterations::  87%|████████▋ | 1367/1563 [00:03<00:00, 389.56it/s]\u001b[A\n",
            "Training - Iterations::  90%|█████████ | 1407/1563 [00:03<00:00, 383.93it/s]\u001b[A\n",
            "Training - Iterations::  93%|█████████▎| 1447/1563 [00:03<00:00, 387.90it/s]\u001b[A\n",
            "Training - Iterations::  95%|█████████▌| 1486/1563 [00:03<00:00, 369.00it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 383.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  27%|██▋       | 85/313 [00:00<00:00, 843.42it/s]\u001b[A\n",
            "Evaluation - Iteration::  54%|█████▍    | 170/313 [00:00<00:00, 531.90it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 641.72it/s]\n",
            "Epochs:  60%|██████    | 6/10 [00:29<00:18,  4.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 5\n",
            "\u001b[1mTrain loss\u001b[1m: 1.8129318952560425.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 44.768.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 1.8055120706558228.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 61.8.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   2%|▏         | 36/1563 [00:00<00:04, 356.76it/s]\u001b[A\n",
            "Training - Iterations::   5%|▍         | 77/1563 [00:00<00:03, 382.01it/s]\u001b[A\n",
            "Training - Iterations::   7%|▋         | 116/1563 [00:00<00:04, 355.14it/s]\u001b[A\n",
            "Training - Iterations::  10%|▉         | 152/1563 [00:00<00:04, 325.32it/s]\u001b[A\n",
            "Training - Iterations::  12%|█▏        | 185/1563 [00:00<00:05, 243.23it/s]\u001b[A\n",
            "Training - Iterations::  14%|█▎        | 213/1563 [00:00<00:05, 252.65it/s]\u001b[A\n",
            "Training - Iterations::  16%|█▋        | 254/1563 [00:00<00:04, 292.95it/s]\u001b[A\n",
            "Training - Iterations::  19%|█▉        | 295/1563 [00:00<00:03, 325.08it/s]\u001b[A\n",
            "Training - Iterations::  21%|██▏       | 334/1563 [00:01<00:03, 342.34it/s]\u001b[A\n",
            "Training - Iterations::  24%|██▎       | 371/1563 [00:01<00:03, 348.89it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 407/1563 [00:01<00:03, 345.87it/s]\u001b[A\n",
            "Training - Iterations::  28%|██▊       | 443/1563 [00:01<00:04, 239.98it/s]\u001b[A\n",
            "Training - Iterations::  31%|███       | 478/1563 [00:01<00:04, 263.27it/s]\u001b[A\n",
            "Training - Iterations::  33%|███▎      | 521/1563 [00:01<00:03, 301.86it/s]\u001b[A\n",
            "Training - Iterations::  36%|███▌      | 561/1563 [00:01<00:03, 324.58it/s]\u001b[A\n",
            "Training - Iterations::  38%|███▊      | 597/1563 [00:01<00:03, 315.39it/s]\u001b[A\n",
            "Training - Iterations::  40%|████      | 631/1563 [00:02<00:03, 302.17it/s]\u001b[A\n",
            "Training - Iterations::  42%|████▏     | 663/1563 [00:02<00:03, 294.03it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▍     | 694/1563 [00:02<00:03, 285.93it/s]\u001b[A\n",
            "Training - Iterations::  46%|████▋     | 724/1563 [00:02<00:02, 287.35it/s]\u001b[A\n",
            "Training - Iterations::  48%|████▊     | 755/1563 [00:02<00:02, 292.55it/s]\u001b[A\n",
            "Training - Iterations::  50%|█████     | 788/1563 [00:02<00:02, 301.07it/s]\u001b[A\n",
            "Training - Iterations::  52%|█████▏    | 820/1563 [00:02<00:02, 306.42it/s]\u001b[A\n",
            "Training - Iterations::  55%|█████▍    | 853/1563 [00:02<00:02, 310.83it/s]\u001b[A\n",
            "Training - Iterations::  57%|█████▋    | 887/1563 [00:02<00:02, 318.82it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▉    | 920/1563 [00:03<00:02, 320.32it/s]\u001b[A\n",
            "Training - Iterations::  61%|██████    | 956/1563 [00:03<00:01, 327.81it/s]\u001b[A\n",
            "Training - Iterations::  63%|██████▎   | 989/1563 [00:03<00:01, 311.17it/s]\u001b[A\n",
            "Training - Iterations::  65%|██████▌   | 1021/1563 [00:03<00:01, 291.83it/s]\u001b[A\n",
            "Training - Iterations::  67%|██████▋   | 1051/1563 [00:03<00:01, 290.58it/s]\u001b[A\n",
            "Training - Iterations::  69%|██████▉   | 1084/1563 [00:03<00:01, 299.24it/s]\u001b[A\n",
            "Training - Iterations::  71%|███████▏  | 1115/1563 [00:03<00:01, 293.66it/s]\u001b[A\n",
            "Training - Iterations::  73%|███████▎  | 1146/1563 [00:03<00:01, 296.62it/s]\u001b[A\n",
            "Training - Iterations::  75%|███████▌  | 1176/1563 [00:03<00:01, 292.20it/s]\u001b[A\n",
            "Training - Iterations::  77%|███████▋  | 1208/1563 [00:03<00:01, 300.09it/s]\u001b[A\n",
            "Training - Iterations::  79%|███████▉  | 1240/1563 [00:04<00:01, 304.14it/s]\u001b[A\n",
            "Training - Iterations::  81%|████████▏ | 1271/1563 [00:04<00:01, 279.01it/s]\u001b[A\n",
            "Training - Iterations::  83%|████████▎ | 1300/1563 [00:04<00:00, 274.17it/s]\u001b[A\n",
            "Training - Iterations::  85%|████████▍ | 1328/1563 [00:04<00:00, 269.08it/s]\u001b[A\n",
            "Training - Iterations::  87%|████████▋ | 1363/1563 [00:04<00:00, 290.84it/s]\u001b[A\n",
            "Training - Iterations::  90%|████████▉ | 1403/1563 [00:04<00:00, 321.34it/s]\u001b[A\n",
            "Training - Iterations::  92%|█████████▏| 1444/1563 [00:04<00:00, 346.44it/s]\u001b[A\n",
            "Training - Iterations::  95%|█████████▍| 1484/1563 [00:04<00:00, 359.09it/s]\u001b[A\n",
            "Training - Iterations::  97%|█████████▋| 1523/1563 [00:04<00:00, 368.00it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:05<00:00, 308.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 6.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  32%|███▏      | 100/313 [00:00<00:00, 998.37it/s]\u001b[A\n",
            "Evaluation - Iteration::  64%|██████▍   | 200/313 [00:00<00:00, 829.47it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 863.99it/s]\n",
            "Epochs:  70%|███████   | 7/10 [00:34<00:14,  4.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 6\n",
            "\u001b[1mTrain loss\u001b[1m: 1.4657412767410278.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 55.38999999999999.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 1.3909088373184204.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 67.77.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 41/1563 [00:00<00:03, 403.61it/s]\u001b[A\n",
            "Training - Iterations::   5%|▌         | 82/1563 [00:00<00:03, 405.68it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 123/1563 [00:00<00:03, 403.52it/s]\u001b[A\n",
            "Training - Iterations::  10%|█         | 164/1563 [00:00<00:03, 367.30it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 204/1563 [00:00<00:03, 378.06it/s]\u001b[A\n",
            "Training - Iterations::  16%|█▌        | 243/1563 [00:00<00:03, 373.62it/s]\u001b[A\n",
            "Training - Iterations::  18%|█▊        | 283/1563 [00:00<00:03, 381.18it/s]\u001b[A\n",
            "Training - Iterations::  21%|██        | 322/1563 [00:00<00:03, 353.44it/s]\u001b[A\n",
            "Training - Iterations::  23%|██▎       | 358/1563 [00:00<00:03, 355.11it/s]\u001b[A\n",
            "Training - Iterations::  25%|██▌       | 398/1563 [00:01<00:03, 367.92it/s]\u001b[A\n",
            "Training - Iterations::  28%|██▊       | 440/1563 [00:01<00:02, 380.81it/s]\u001b[A\n",
            "Training - Iterations::  31%|███       | 480/1563 [00:01<00:02, 385.50it/s]\u001b[A\n",
            "Training - Iterations::  33%|███▎      | 521/1563 [00:01<00:02, 391.55it/s]\u001b[A\n",
            "Training - Iterations::  36%|███▌      | 561/1563 [00:01<00:02, 388.30it/s]\u001b[A\n",
            "Training - Iterations::  38%|███▊      | 601/1563 [00:01<00:02, 389.26it/s]\u001b[A\n",
            "Training - Iterations::  41%|████      | 640/1563 [00:01<00:02, 385.26it/s]\u001b[A\n",
            "Training - Iterations::  43%|████▎     | 679/1563 [00:01<00:02, 381.08it/s]\u001b[A\n",
            "Training - Iterations::  46%|████▌     | 718/1563 [00:01<00:02, 357.64it/s]\u001b[A\n",
            "Training - Iterations::  48%|████▊     | 757/1563 [00:02<00:02, 364.97it/s]\u001b[A\n",
            "Training - Iterations::  51%|█████     | 797/1563 [00:02<00:02, 373.00it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▎    | 837/1563 [00:02<00:01, 379.44it/s]\u001b[A\n",
            "Training - Iterations::  56%|█████▌    | 876/1563 [00:02<00:01, 381.26it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▊    | 915/1563 [00:02<00:01, 381.89it/s]\u001b[A\n",
            "Training - Iterations::  61%|██████    | 956/1563 [00:02<00:01, 387.53it/s]\u001b[A\n",
            "Training - Iterations::  64%|██████▎   | 995/1563 [00:02<00:01, 386.65it/s]\u001b[A\n",
            "Training - Iterations::  66%|██████▋   | 1037/1563 [00:02<00:01, 395.44it/s]\u001b[A\n",
            "Training - Iterations::  69%|██████▉   | 1077/1563 [00:02<00:01, 374.21it/s]\u001b[A\n",
            "Training - Iterations::  71%|███████▏  | 1115/1563 [00:02<00:01, 368.00it/s]\u001b[A\n",
            "Training - Iterations::  74%|███████▍  | 1155/1563 [00:03<00:01, 375.58it/s]\u001b[A\n",
            "Training - Iterations::  77%|███████▋  | 1196/1563 [00:03<00:00, 384.98it/s]\u001b[A\n",
            "Training - Iterations::  79%|███████▉  | 1236/1563 [00:03<00:00, 388.53it/s]\u001b[A\n",
            "Training - Iterations::  82%|████████▏ | 1279/1563 [00:03<00:00, 398.26it/s]\u001b[A\n",
            "Training - Iterations::  84%|████████▍ | 1319/1563 [00:03<00:00, 398.44it/s]\u001b[A\n",
            "Training - Iterations::  87%|████████▋ | 1361/1563 [00:03<00:00, 403.90it/s]\u001b[A\n",
            "Training - Iterations::  90%|████████▉ | 1402/1563 [00:03<00:00, 404.79it/s]\u001b[A\n",
            "Training - Iterations::  92%|█████████▏| 1443/1563 [00:03<00:00, 399.30it/s]\u001b[A\n",
            "Training - Iterations::  95%|█████████▍| 1483/1563 [00:03<00:00, 377.02it/s]\u001b[A\n",
            "Training - Iterations::  97%|█████████▋| 1521/1563 [00:03<00:00, 376.64it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 381.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 7.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  34%|███▍      | 107/313 [00:00<00:00, 1064.22it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 1010.38it/s]\n",
            "Epochs:  80%|████████  | 8/10 [00:39<00:09,  4.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 7\n",
            "\u001b[1mTrain loss\u001b[1m: 1.1476881504058838.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 63.434000000000005.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 1.2632114887237549.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 72.71.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 41/1563 [00:00<00:03, 409.72it/s]\u001b[A\n",
            "Training - Iterations::   5%|▌         | 82/1563 [00:00<00:03, 391.51it/s]\u001b[A\n",
            "Training - Iterations::   8%|▊         | 124/1563 [00:00<00:03, 400.71it/s]\u001b[A\n",
            "Training - Iterations::  11%|█         | 165/1563 [00:00<00:03, 365.46it/s]\u001b[A\n",
            "Training - Iterations::  13%|█▎        | 202/1563 [00:00<00:03, 355.54it/s]\u001b[A\n",
            "Training - Iterations::  15%|█▌        | 242/1563 [00:00<00:03, 367.60it/s]\u001b[A\n",
            "Training - Iterations::  18%|█▊        | 284/1563 [00:00<00:03, 381.84it/s]\u001b[A\n",
            "Training - Iterations::  21%|██        | 323/1563 [00:00<00:03, 381.14it/s]\u001b[A\n",
            "Training - Iterations::  23%|██▎       | 364/1563 [00:00<00:03, 389.11it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 404/1563 [00:01<00:02, 388.34it/s]\u001b[A\n",
            "Training - Iterations::  28%|██▊       | 445/1563 [00:01<00:02, 392.41it/s]\u001b[A\n",
            "Training - Iterations::  31%|███       | 485/1563 [00:01<00:02, 385.77it/s]\u001b[A\n",
            "Training - Iterations::  34%|███▎      | 524/1563 [00:01<00:02, 376.11it/s]\u001b[A\n",
            "Training - Iterations::  36%|███▌      | 562/1563 [00:01<00:02, 366.67it/s]\u001b[A\n",
            "Training - Iterations::  38%|███▊      | 599/1563 [00:01<00:02, 361.21it/s]\u001b[A\n",
            "Training - Iterations::  41%|████      | 640/1563 [00:01<00:02, 374.04it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▎     | 680/1563 [00:01<00:02, 381.46it/s]\u001b[A\n",
            "Training - Iterations::  46%|████▌     | 721/1563 [00:01<00:02, 388.62it/s]\u001b[A\n",
            "Training - Iterations::  49%|████▊     | 760/1563 [00:01<00:02, 388.62it/s]\u001b[A\n",
            "Training - Iterations::  51%|█████     | 801/1563 [00:02<00:01, 392.94it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▍    | 841/1563 [00:02<00:01, 394.05it/s]\u001b[A\n",
            "Training - Iterations::  56%|█████▋    | 881/1563 [00:02<00:01, 387.45it/s]\u001b[A\n",
            "Training - Iterations::  59%|█████▉    | 920/1563 [00:02<00:01, 362.86it/s]\u001b[A\n",
            "Training - Iterations::  61%|██████▏   | 959/1563 [00:02<00:01, 368.86it/s]\u001b[A\n",
            "Training - Iterations::  64%|██████▍   | 997/1563 [00:02<00:01, 371.27it/s]\u001b[A\n",
            "Training - Iterations::  66%|██████▋   | 1038/1563 [00:02<00:01, 380.92it/s]\u001b[A\n",
            "Training - Iterations::  69%|██████▉   | 1078/1563 [00:02<00:01, 385.02it/s]\u001b[A\n",
            "Training - Iterations::  72%|███████▏  | 1119/1563 [00:02<00:01, 390.35it/s]\u001b[A\n",
            "Training - Iterations::  74%|███████▍  | 1159/1563 [00:03<00:01, 390.89it/s]\u001b[A\n",
            "Training - Iterations::  77%|███████▋  | 1201/1563 [00:03<00:00, 397.01it/s]\u001b[A\n",
            "Training - Iterations::  79%|███████▉  | 1241/1563 [00:03<00:00, 394.38it/s]\u001b[A\n",
            "Training - Iterations::  82%|████████▏ | 1281/1563 [00:03<00:00, 390.65it/s]\u001b[A\n",
            "Training - Iterations::  85%|████████▍ | 1321/1563 [00:03<00:00, 367.28it/s]\u001b[A\n",
            "Training - Iterations::  87%|████████▋ | 1360/1563 [00:03<00:00, 372.61it/s]\u001b[A\n",
            "Training - Iterations::  89%|████████▉ | 1398/1563 [00:03<00:00, 373.96it/s]\u001b[A\n",
            "Training - Iterations::  92%|█████████▏| 1439/1563 [00:03<00:00, 383.31it/s]\u001b[A\n",
            "Training - Iterations::  95%|█████████▍| 1479/1563 [00:03<00:00, 387.12it/s]\u001b[A\n",
            "Training - Iterations::  97%|█████████▋| 1520/1563 [00:03<00:00, 392.18it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 381.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 8.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  32%|███▏      | 99/313 [00:00<00:00, 986.65it/s]\u001b[A\n",
            "Evaluation - Iteration::  64%|██████▎   | 199/313 [00:00<00:00, 990.83it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 875.62it/s]\n",
            "Epochs:  90%|█████████ | 9/10 [00:43<00:04,  4.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 8\n",
            "\u001b[1mTrain loss\u001b[1m: 0.9415963888168335.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 70.15.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 0.7444537281990051.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 77.5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training - Iterations::   0%|          | 0/1563 [00:00<?, ?it/s]\u001b[A\n",
            "Training - Iterations::   3%|▎         | 41/1563 [00:00<00:03, 401.56it/s]\u001b[A\n",
            "Training - Iterations::   5%|▌         | 82/1563 [00:00<00:04, 332.17it/s]\u001b[A\n",
            "Training - Iterations::   7%|▋         | 116/1563 [00:00<00:04, 316.40it/s]\u001b[A\n",
            "Training - Iterations::   9%|▉         | 148/1563 [00:00<00:04, 309.08it/s]\u001b[A\n",
            "Training - Iterations::  12%|█▏        | 180/1563 [00:00<00:04, 309.26it/s]\u001b[A\n",
            "Training - Iterations::  14%|█▎        | 212/1563 [00:00<00:04, 308.52it/s]\u001b[A\n",
            "Training - Iterations::  16%|█▌        | 246/1563 [00:00<00:04, 317.86it/s]\u001b[A\n",
            "Training - Iterations::  18%|█▊        | 278/1563 [00:00<00:04, 306.08it/s]\u001b[A\n",
            "Training - Iterations::  20%|█▉        | 309/1563 [00:00<00:04, 296.47it/s]\u001b[A\n",
            "Training - Iterations::  22%|██▏       | 339/1563 [00:01<00:04, 296.54it/s]\u001b[A\n",
            "Training - Iterations::  24%|██▎       | 369/1563 [00:01<00:04, 290.18it/s]\u001b[A\n",
            "Training - Iterations::  26%|██▌       | 401/1563 [00:01<00:03, 298.39it/s]\u001b[A\n",
            "Training - Iterations::  28%|██▊       | 437/1563 [00:01<00:03, 314.96it/s]\u001b[A\n",
            "Training - Iterations::  30%|███       | 471/1563 [00:01<00:03, 322.28it/s]\u001b[A\n",
            "Training - Iterations::  32%|███▏      | 504/1563 [00:01<00:03, 318.73it/s]\u001b[A\n",
            "Training - Iterations::  34%|███▍      | 536/1563 [00:01<00:03, 306.83it/s]\u001b[A\n",
            "Training - Iterations::  36%|███▋      | 568/1563 [00:01<00:03, 309.08it/s]\u001b[A\n",
            "Training - Iterations::  38%|███▊      | 600/1563 [00:01<00:03, 290.83it/s]\u001b[A\n",
            "Training - Iterations::  40%|████      | 630/1563 [00:02<00:03, 285.17it/s]\u001b[A\n",
            "Training - Iterations::  42%|████▏     | 660/1563 [00:02<00:03, 286.77it/s]\u001b[A\n",
            "Training - Iterations::  44%|████▍     | 689/1563 [00:02<00:03, 285.84it/s]\u001b[A\n",
            "Training - Iterations::  46%|████▌     | 720/1563 [00:02<00:02, 292.42it/s]\u001b[A\n",
            "Training - Iterations::  48%|████▊     | 752/1563 [00:02<00:02, 299.22it/s]\u001b[A\n",
            "Training - Iterations::  50%|█████     | 784/1563 [00:02<00:02, 303.94it/s]\u001b[A\n",
            "Training - Iterations::  52%|█████▏    | 815/1563 [00:02<00:02, 299.56it/s]\u001b[A\n",
            "Training - Iterations::  54%|█████▍    | 846/1563 [00:02<00:02, 296.48it/s]\u001b[A\n",
            "Training - Iterations::  56%|█████▌    | 876/1563 [00:02<00:02, 281.88it/s]\u001b[A\n",
            "Training - Iterations::  58%|█████▊    | 905/1563 [00:03<00:02, 274.62it/s]\u001b[A\n",
            "Training - Iterations::  60%|██████    | 943/1563 [00:03<00:02, 304.10it/s]\u001b[A\n",
            "Training - Iterations::  63%|██████▎   | 984/1563 [00:03<00:01, 333.29it/s]\u001b[A\n",
            "Training - Iterations::  65%|██████▌   | 1020/1563 [00:03<00:01, 339.99it/s]\u001b[A\n",
            "Training - Iterations::  68%|██████▊   | 1060/1563 [00:03<00:01, 356.76it/s]\u001b[A\n",
            "Training - Iterations::  70%|███████   | 1099/1563 [00:03<00:01, 364.85it/s]\u001b[A\n",
            "Training - Iterations::  73%|███████▎  | 1140/1563 [00:03<00:01, 377.25it/s]\u001b[A\n",
            "Training - Iterations::  75%|███████▌  | 1180/1563 [00:03<00:01, 379.69it/s]\u001b[A\n",
            "Training - Iterations::  78%|███████▊  | 1220/1563 [00:03<00:00, 384.35it/s]\u001b[A\n",
            "Training - Iterations::  81%|████████  | 1259/1563 [00:03<00:00, 361.63it/s]\u001b[A\n",
            "Training - Iterations::  83%|████████▎ | 1299/1563 [00:04<00:00, 371.80it/s]\u001b[A\n",
            "Training - Iterations::  86%|████████▌ | 1340/1563 [00:04<00:00, 381.39it/s]\u001b[A\n",
            "Training - Iterations::  88%|████████▊ | 1380/1563 [00:04<00:00, 384.65it/s]\u001b[A\n",
            "Training - Iterations::  91%|█████████ | 1419/1563 [00:04<00:00, 381.43it/s]\u001b[A\n",
            "Training - Iterations::  93%|█████████▎| 1459/1563 [00:04<00:00, 385.20it/s]\u001b[A\n",
            "Training - Iterations::  96%|█████████▌| 1499/1563 [00:04<00:00, 387.40it/s]\u001b[A\n",
            "Training - Iterations:: 100%|██████████| 1563/1563 [00:04<00:00, 330.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model at epoch: 9.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation - Iteration::   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluation - Iteration::  32%|███▏      | 100/313 [00:00<00:00, 997.79it/s]\u001b[A\n",
            "Evaluation - Iteration::  64%|██████▍   | 200/313 [00:00<00:00, 857.91it/s]\u001b[A\n",
            "Evaluation - Iteration:: 100%|██████████| 313/313 [00:00<00:00, 877.60it/s]\n",
            "Epochs: 100%|██████████| 10/10 [00:48<00:00,  4.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch\u001b[1m: 9\n",
            "\u001b[1mTrain loss\u001b[1m: 0.856215238571167.\n",
            "\u001b[1mTrain accuracy[%]\u001b[1m: 74.92999999999999.\n",
            "\u001b[1mCross-validation loss\u001b[1m: 0.5227481722831726.\n",
            "\u001b[1mCross-validation accuracy[%]\u001b[1m: 79.61.\n",
            "Train finished.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training performed\n",
        "if not(skip_training):\n",
        "\n",
        "  # Placeholder for training loss\n",
        "  train_loss_list=[]\n",
        "  # Placeholder for validation loss\n",
        "  cv_loss_list=[]\n",
        "\n",
        "  # If GPU is available and selected, model is moved to GPU.\n",
        "  if torch.cuda.is_available():\n",
        "    model=model.cuda()\n",
        "\n",
        "  # Start training - looping over n_epochs.\n",
        "  for epoch in tqdm(range(n_epochs), desc=\"Epochs\"):\n",
        "      # Setting up the model to perform training.\n",
        "      model.train()\n",
        "\n",
        "      # Number of correct predictions for train split\n",
        "      train_correct = 0\n",
        "      # Number of total predictions for train split\n",
        "      train_total = 0\n",
        "      # Perform mini-batch training, i.e., splitting training into a certain number of batches.\n",
        "      for x_train_batch, y_train_batch in tqdm(train_loader, desc='Training - Iterations:'):\n",
        "          # If GPU is available and selected, data are moved to GPU.\n",
        "          if torch.cuda.is_available():\n",
        "            # Move to GPU\n",
        "            x_train_batch=x_train_batch.cuda()\n",
        "            y_train_batch=y_train_batch.cuda()\n",
        "\n",
        "          # Setting the gradient to zero.\n",
        "          optimizer.zero_grad()\n",
        "          # Calculating the predictions on the batch.\n",
        "          y_pred_train = model(x_train_batch)\n",
        "          # Calculating the loss between Y_pred and the y_train_batch (targets).\n",
        "          train_loss = loss(y_pred_train, y_train_batch)\n",
        "          # Back-propagting the loss, i.e., calculating the weight increments in the different layers.\n",
        "          train_loss.backward()\n",
        "          # Updating weights by using SGD optimizer.\n",
        "          optimizer.step()\n",
        "          # Extracting predicted class.\n",
        "          y_train_predicted_class = torch.max(y_pred_train, 1)[1]\n",
        "          # Updating total and number of corrected patches\n",
        "          train_correct += (y_train_predicted_class == y_train_batch).sum().item()\n",
        "          train_total += y_train_batch.size(0)\n",
        "\n",
        "      # Calculating training accuracy\n",
        "      train_accuracy = train_correct/train_total * 100\n",
        "\n",
        "      # Append training loss values at the end of an epoch\n",
        "      train_loss_list.append(train_loss)\n",
        "\n",
        "\n",
        "      print(f'Evaluating model at epoch: {epoch}.')\n",
        "\n",
        "      # Setting up the model to perform the inference (some layers in the model behave differently during the training and inference)\n",
        "      model.eval()\n",
        "\n",
        "      # Number of correct predictions for cross validation split\n",
        "      cv_correct = 0\n",
        "      # Number of total predictions for cross validation split\n",
        "      cv_total = 0\n",
        "\n",
        "      # Evaluating model on the cross-validation split. Since we are not training, we do not need to calculate gradients.\n",
        "      with torch.no_grad():\n",
        "          # Splitting cross-validation into batches.\n",
        "          for x_cv_batch, y_cv_batch in tqdm(valid_loader, desc='Evaluation - Iteration:'):\n",
        "              # Moving batches to the GPU if available\n",
        "              if torch.cuda.is_available():\n",
        "                  x_cv_batch=x_cv_batch.cuda()\n",
        "                  y_cv_batch=y_cv_batch.cuda()\n",
        "\n",
        "              # Performing evaluation on the cross-valiation split.\n",
        "              y_cv_pred = model(x_cv_batch)\n",
        "              # Extracting loss on the cross-valiation split.\n",
        "              cv_loss = loss(y_cv_pred, y_cv_batch)\n",
        "              # Extracting predicted class.\n",
        "              y_cv_predicted_class =  torch.max(y_cv_pred, 1)[1]\n",
        "              # Updating total and number of corrected patches\n",
        "              cv_total += y_cv_batch.size(0)\n",
        "              cv_correct += (y_cv_predicted_class == y_cv_batch).sum().item()\n",
        "          # Calculating the evaluation accuracy\n",
        "          cv_accuracy = cv_correct/cv_total * 100\n",
        "\n",
        "          # Append validation loss values at the end\n",
        "          cv_loss_list.append(cv_loss)\n",
        "\n",
        "      # Print information\n",
        "      print(f\"\\033[1mEpoch\\033[1m: {str(epoch)}\")\n",
        "      print(f\"\\033[1mTrain loss\\033[1m: {str(float(train_loss))}.\")\n",
        "      print(f\"\\033[1mTrain accuracy[%]\\033[1m: {str(train_accuracy)}.\")\n",
        "      print(f\"\\033[1mCross-validation loss\\033[1m: {str(float(cv_loss))}.\")\n",
        "      print(f\"\\033[1mCross-validation accuracy[%]\\033[1m: {str(cv_accuracy)}.\")\n",
        "\n",
        "  # Saving best model\n",
        "  torch.save(model.state_dict(), \"trained_model.pth\")\n",
        "  print(\"Train finished.\")\n",
        "else:\n",
        "  print(\"Skipping training...\")\n",
        "  try:\n",
        "    # Load loss values from file\n",
        "    with open('losses.pkl', \"rb\") as f:  # Python 3: open(..., 'rb')\n",
        "      train_loss_list, cv_loss_list = pickle.load(f)\n",
        "  except:\n",
        "    raise ValueError(\"It seems you have missed some files from Brightspace. One or both the losses values were missing. Please, upload them and execute this cell again or try to do the training.\")\n",
        "  try:\n",
        "    model.load_state_dict(torch.load(\"trained_model.pth\"))\n",
        "  except:\n",
        "    raise ValueError(\"It seems you are using a different model from the default one (strong) or the \"\"trained_model.pth\"\" file is missing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2srK0XP6_Sp"
      },
      "source": [
        "## 6 - Monitor training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZx5FavOFhNb"
      },
      "source": [
        "### 6.1 - Plotting loss values over training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-54KoiP7HOH"
      },
      "source": [
        "The next cell will show the training results. If you used the model with defaults values of parameters and `test_overfitting=False`, training should have gone well. In this case, both the **train** and **cross-validation** losses should have sufficiently decreased during training. <br> If you had experimented **overfitting**, only the loss function on the training set should have decreased much more than the one into cross validation split. <br>\n",
        "In case of **underfitting** both the loss have decreased very few."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "9ySzwyPF0U6Y",
        "outputId": "8bb5c2c4-ca66-4b8e-f93f-91eb46e2d5d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Preparation for plot. Moving losses from GPU to CPU (required by matplotlib) and converting them to list.\n",
        "if torch.is_tensor(train_loss_list[0]):\n",
        "   train_loss_list=[float(x.detach().cpu()) for x in train_loss_list]\n",
        "\n",
        "if torch.is_tensor(cv_loss_list[0]):\n",
        "   cv_loss_list=[float(x.detach().cpu()) for x in cv_loss_list]\n",
        "plt.plot(range(len(train_loss_list)), train_loss_list,'r')\n",
        "plt.plot(range(len(cv_loss_list)), cv_loss_list, 'g')\n",
        "plt.legend([\"train loss\", \"cv loss\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W8uVHDFb69lU"
      },
      "outputs": [],
      "source": [
        "with open('losses.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([train_loss_list, cv_loss_list], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhEE5_xX6ph_"
      },
      "source": [
        "## 6.2 - Measuring accuracy on the test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a9M5_3FFsdU"
      },
      "source": [
        "The next cell will measure the accuracy that the trained model achieves on the test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORg7K-Cy2qtz",
        "outputId": "1fb3528d-5917-4951-ee53-accb713f7dbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test - Iteration:: 100%|██████████| 313/313 [00:01<00:00, 165.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mTest accuracy[%]\u001b[1m: 80.07\n"
          ]
        }
      ],
      "source": [
        "# Set model to evaluation model (some layers, as dropout will change their behaviour)\n",
        "model.eval()\n",
        "\n",
        "# Number of correct predictions for test split\n",
        "test_correct = 0\n",
        "# Number of total predictions for test split\n",
        "test_total = 0\n",
        "\n",
        "# Prediction placeholders\n",
        "predictions=[]\n",
        "\n",
        "# Target placeholders\n",
        "targets=[]\n",
        "\n",
        "# Images placeholders\n",
        "images=[]\n",
        "\n",
        "# Moving model to GPU if CUDA is available.\n",
        "if torch.cuda.is_available():\n",
        "    model=model.cuda()\n",
        "\n",
        "# Evaluating model on the test split. Since we are not training, we do not need to calculate gradients.\n",
        "with torch.no_grad():\n",
        "    # Splitting cross-validation into batches.\n",
        "    for x_test_batch, y_test_batch in tqdm(test_loader, desc='Test - Iteration:'):\n",
        "        # Moving batches to GPU if CUDA is available.\n",
        "        if torch.cuda.is_available():\n",
        "            x_test_batch=x_test_batch.cuda()\n",
        "            y_test_batch=y_test_batch.cuda()\n",
        "\n",
        "        # Performing evaluation on the test split.\n",
        "        y_test_pred = model(x_test_batch)\n",
        "        # Extracting predicted class.\n",
        "        y_test_predicted_class =  torch.max(y_test_pred, 1)[1]\n",
        "        # Updating total and number of corrected patches\n",
        "        test_total += y_test_batch.size(0)\n",
        "        test_correct += (y_test_predicted_class == y_test_batch).sum().item()\n",
        "        # Stacking predictions, targets, and images.\n",
        "        predictions+=list(y_test_predicted_class)\n",
        "        targets+=list(y_test_batch)\n",
        "        images+=list(x_test_batch)\n",
        "    # Calculating the evaluation accuracy\n",
        "    test_accuracy = test_correct/test_total * 100\n",
        "\n",
        "print('\\033[1mTest accuracy[%]\\033[1m: ' +str(float(test_accuracy)))\n",
        "\n",
        "# Moving predictions, images and targets to CPU\n",
        "predictions=[x.detach().cpu().numpy() for x in predictions]\n",
        "targets=[x.detach().cpu().numpy() for x in targets]\n",
        "images=[x.detach().cpu().numpy() for x in images]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZGdO5hyGqsk"
      },
      "source": [
        "## 6.3 - Show predictions on random images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eNHz3fNGq7J"
      },
      "source": [
        "The next cell will take randome examples from the test split and showcases the predicted class (**predicted**) versus the (**expected**) class. <br> This is done through the `plot_random_samples` included in the `utils.py` file.\n",
        "If you have set `test_overfitting` to `True`, you will see the model will be in general capable to predict correctly all the classes but `8` and `9`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_aoBnbC9ICmy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_samples(samples, targets, predictions):\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
        "  for i, ax in enumerate(axes):\n",
        "    sample = samples[i].reshape(28, 28) # Reshape to (28, 28)\n",
        "    ax.imshow(sample, cmap='gray')\n",
        "    ax.set_title(f'True: {targets[i]} | Pred: {predictions[i]}')\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "sCFOZrTqIPzH",
        "outputId": "ee972485-159a-4cd7-e37d-b339fb606ba7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_samples(images, targets, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF7RI90QlToq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
