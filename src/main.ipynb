{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.8 environment at: C:\\Users\\jesse\\Documents\\TU Delft\\MSE git\\img_classification\\.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(os.getcwd(), \"../training_data/EuroSAT_RGB\")\n",
    "\n",
    "BATCH_SIZE = 1500\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = datasets.ImageFolder(root=DATASET_PATH, transform=transform)\n",
    "\n",
    "# Split into training and validation set\n",
    "train_idx, val_idx = train_test_split(\n",
    "  range(len(dataset_full)),       # Size of the full dataset\n",
    "  test_size=TEST_SIZE,            # Fraction used for validation (test)\n",
    "  stratify=dataset_full.targets   # Ensure class distribution is preserved\n",
    ")\n",
    "\n",
    "# Create the training and validation set\n",
    "dataset_train = Subset(dataset_full, train_idx)\n",
    "dataset_val = Subset(dataset_full, val_idx)\n",
    "\n",
    "# TODO: Investigate if the DataLoader should shuffle the data\n",
    "loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "loader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Show all the class labels\n",
    "# print(dataset_full.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "# Adjust to the amount of classes\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, len(dataset_full.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set up loss function\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d935d3e2f0e74a74922e13d77816bb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc857e54ab4745bea29f268705599ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86335793a7264238a2e15491f1069d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e9b2a75a5d42e2aafbc541c442fea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f875f903478d44c1bf6f20934b24dda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a185119b00d7447aa06fc31247ee863a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0879a888c34bae8891e82ae57e957a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171514ccf1094b0686d96e0634bdccf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103313b3b137413b920a6f9bf5113ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d5c567cbd3442aaf5c77d8a9eb0ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb27f688a1f4d5f95b3a013e2774e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491b2baf2a124ffdbc910d92f3ef57ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7a9ee4c9254150b4607c1a45ae4c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62ec0b5a36941eda14db31c7dc264d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f720ae3089bd49bf9c25d7edbd7f993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe0b151bc94422ebac4e725b2e97ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec5b79cccea4771b1cce90faf3526f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e98498ab4b45f98dd443b03b271185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d434641bd748ae98c405c22ad49545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3773a2f399b146e8934afb59ed67a13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training - batch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3010b6d74943fa8a17acb8dbd76276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation - batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n",
      "Elapsed time: 117.93 seconds\n"
     ]
    }
   ],
   "source": [
    "if not(skip_training):\n",
    "\n",
    "  # Track time\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Holder for training loss\n",
    "  train_loss = []\n",
    "  # Holder for validation loss\n",
    "  validation_loss = []\n",
    "\n",
    "  for epoch in tqdm(range(EPOCHS), desc='Epochs'):\n",
    "\n",
    "    # Setup model to perform training\n",
    "    model.train()\n",
    "\n",
    "    loss_train = 0\n",
    "    # Number of correct predictions for train split\n",
    "    train_correct = 0\n",
    "    # Number of total predictions for train split\n",
    "    train_total = 0\n",
    "\n",
    "    # Perform training in batches\n",
    "    for inputs, labels in tqdm(loader_train, desc=\"Training - batch\"):\n",
    "      # Move data to device (CPU or GPU)\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      # Zero the gradients\n",
    "      optimizer.zero_grad()\n",
    "      # Calculate the predictions (outputs) on the batch\n",
    "      outputs = model(inputs)\n",
    "      # Calculate the loss (error) between predictions and labels\n",
    "      train_loss = loss(outputs, labels)\n",
    "      # Back propagate the error and update the weights\n",
    "      train_loss.backward()\n",
    "      # Update the weights using the SGD optimizer\n",
    "      optimizer.step()\n",
    "      # Extract the predicted class\n",
    "      predicted  torch.max(outputs, 1)[1]\n",
    "      # Update the total and number of correct\n",
    "      train_correct += (predicted == labels).sum().item()\n",
    "      train_total += labels.size(0) \n",
    "\n",
    "    # train_acc = 100. * correct / total\n",
    "\n",
    "    # Setup model to perform validation (inference)\n",
    "    model.eval()\n",
    "\n",
    "    # Number of correct predictions for validation split\n",
    "    val_correct = 0\n",
    "    # Number of total predictions for validation split\n",
    "    val_total = 0\n",
    "\n",
    "    # Validate model using the validation set, the gradients do not need to be calculated\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in tqdm(loader_val, desc=\"Validation - batch\"):\n",
    "        # Move data to device (CPU or GPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Calculate the predictions (outputs) on the batch\n",
    "        outputs = model(inputs)\n",
    "        # Calculate the loss (error) between predictions and labels\n",
    "        val_loss = loss(outputs, labels)\n",
    "\n",
    "  # Saving the model\n",
    "  torch.save(model.state_dict(), \"model.pth\")\n",
    "  print(\"Model trained\")\n",
    "else:\n",
    "  print(\"Skip training...\")\n",
    "  try:\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    print(\"Model loaded\")\n",
    "  except FileNotFoundError:\n",
    "    print(\"Model not found\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses over training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if torch.is_tensor():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
